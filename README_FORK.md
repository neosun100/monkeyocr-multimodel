[English](README_FORK.md) | [ç®€ä½“ä¸­æ–‡](README_FORK_CN.md) | [ç¹é«”ä¸­æ–‡](README_FORK_TW.md) | [æ—¥æœ¬èª](README_FORK_JP.md)

<div align="center">
<h1>MonkeyOCR Multi-Model Fork</h1>
<p>Enhanced Document Parsing with Multi-Model Support for Handwritten Ancient Chinese</p>

[![License](https://img.shields.io/badge/License-Apache%202.0-yellow)](LICENSE.txt)
[![Python](https://img.shields.io/badge/Python-3.10+-blue)](https://python.org)
[![CUDA](https://img.shields.io/badge/CUDA-12.x-green)](https://developer.nvidia.com/cuda-toolkit)
</div>

## ğŸŒŸ What's New in This Fork

This fork extends the original [MonkeyOCR](https://github.com/Yuliang-Liu/MonkeyOCR) with:

- **Multi-Model Support**: Switch between Qwen2.5-VL-3B and Qwen3-VL-8B
- **Enhanced Handwritten Recognition**: Significantly improved accuracy for handwritten ancient Chinese
- **Flexible Configuration**: YAML-based model configuration system
- **Taoist Manuscript Optimization**: Tested and optimized for classical Chinese texts

## ğŸ“Š Model Comparison

| Metric | Qwen2.5-VL-3B | Qwen3-VL-8B |
|--------|---------------|-------------|
| Parameters | 3B | 8B |
| Speed (46 pages) | ~10 min | ~93 min |
| VRAM Usage | ~12GB | ~25-27GB |
| Printed Text | â­â­â­â­ | â­â­â­â­â­ |
| Handwritten | â­â­ | â­â­â­â­â­ |
| Ancient Chinese | â­â­ | â­â­â­â­â­ |

See [detailed comparison report](docs/MULTI_MODEL_COMPARISON.md).

## ğŸš€ Quick Start

### Prerequisites

- Python 3.10+
- CUDA 12.x
- 16GB+ VRAM (for Qwen2.5-VL-3B) or 32GB+ VRAM (for Qwen3-VL-8B)

### Installation

```bash
# Clone repository
git clone https://github.com/neosun100/monkeyocr-multimodel.git
cd monkeyocr-multimodel

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# or: venv\Scripts\activate  # Windows

# Install dependencies
pip install -r requirements.txt

# Download models
python tools/download_model.py -n MonkeyOCR-pro-3B
# Optional: Download Qwen3-VL-8B for better handwritten recognition
# huggingface-cli download Qwen/Qwen3-VL-8B-Instruct --local-dir model_weight/Qwen3-VL-8B-Instruct
```

### Usage

```bash
# Standard parsing (Qwen2.5-VL-3B - fast)
python parse.py input.pdf

# High-accuracy parsing (Qwen3-VL-8B - for handwritten)
python parse.py input.pdf -c model_configs_qwen3vl.yaml

# Batch processing
python parse.py /path/to/folder -g 20
```

## ğŸ³ Docker Deployment

```bash
# Build image
docker compose build monkeyocr

# Run Gradio demo
docker compose up monkeyocr-demo

# Run FastAPI service
docker compose up monkeyocr-api
```

Access:
- Gradio Demo: http://localhost:7860
- API Docs: http://localhost:7861/docs

## âš™ï¸ Configuration

### Model Configuration Files

**Fast Mode** (`model_configs.yaml`):
```yaml
device: cuda
models_dir: model_weight
chat_config:
  model: MonkeyOCR-pro-3B
  backend: lmdeploy
  batch_size: 5
```

**Accuracy Mode** (`model_configs_qwen3vl.yaml`):
```yaml
device: cuda
models_dir: model_weight
chat_config:
  model: Qwen3-VL-8B-Instruct
  backend: qwen3vl
  batch_size: 3
```

### Environment Variables

Copy `.env.example` to `.env` and configure:

```bash
PORT=7870
NVIDIA_VISIBLE_DEVICES=0
GPU_IDLE_TIMEOUT=600
MODEL_NAME=MonkeyOCR-pro-3B
```

## ğŸ“ Project Structure

```
monkeyocr-multimodel/
â”œâ”€â”€ magic_pdf/              # Core parsing library
â”‚   â”œâ”€â”€ model/              # Model implementations
â”‚   â”‚   â”œâ”€â”€ custom_model.py # Multi-model support (Qwen2.5/Qwen3)
â”‚   â”‚   â””â”€â”€ batch_analyze_llm.py
â”‚   â””â”€â”€ ...
â”œâ”€â”€ api/                    # FastAPI service
â”œâ”€â”€ demo/                   # Gradio demo
â”œâ”€â”€ docker/                 # Docker configurations
â”œâ”€â”€ docs/                   # Documentation
â”‚   â”œâ”€â”€ MULTI_MODEL_COMPARISON.md
â”‚   â””â”€â”€ MULTI_MODEL_COMPARISON_CN.md
â”œâ”€â”€ model_configs.yaml      # Default config
â”œâ”€â”€ model_configs_qwen3vl.yaml  # Qwen3-VL config
â”œâ”€â”€ parse.py                # Main entry point
â””â”€â”€ requirements.txt
```

## ğŸ”§ Technical Details

### Key Modifications

1. **Multi-Model Backend**: Added `MonkeyChat_Qwen3VL` class supporting Qwen3-VL-8B
2. **ImageBody OCR**: Enabled OCR for `category_id=3` regions (previously skipped)
3. **Flash Attention**: Auto-detection for both Qwen2.5-VL and Qwen3-VL
4. **Enhanced Prompts**: Optimized prompts for handwritten/ancient text

### Supported Backends

| Backend | Model | Use Case |
|---------|-------|----------|
| `lmdeploy` | MonkeyOCR-pro-3B | Fast, general documents |
| `qwen3vl` | Qwen3-VL-8B | Handwritten, ancient texts |
| `vllm` | Various | High-throughput serving |
| `api` | OpenAI-compatible | External API integration |

## ğŸ“ˆ Benchmark Results

Tested on Taoist manuscript (46 pages, handwritten):

| Character | Qwen2.5-VL-3B | Qwen3-VL-8B | Correct |
|-----------|---------------|-------------|---------|
| é‡‘å…‰ç¯† | é‡‘å…‰è—» âŒ | é‡‘å…‰ç¯† âœ… | ç¯† |
| æ£’æ••ä¸‹äººé—´ | æ£’æ•‘ä¸‹äººé—´ âŒ | æ£’æ••ä¸‹äººé—´ âœ… | æ•• |

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request

## ğŸ“„ License

This project is licensed under the Apache 2.0 License - see [LICENSE.txt](LICENSE.txt).

## ğŸ™ Acknowledgments

- [MonkeyOCR](https://github.com/Yuliang-Liu/MonkeyOCR) - Original project
- [Qwen-VL](https://github.com/QwenLM/Qwen2.5-VL) - Vision-Language models
- [LMDeploy](https://github.com/InternLM/lmdeploy) - Inference framework

## â­ Star History

[![Star History Chart](https://api.star-history.com/svg?repos=neosun100/monkeyocr-multimodel&type=Date)](https://star-history.com/#neosun100/monkeyocr-multimodel)

## ğŸ“± Follow Us

![WeChat](https://img.aws.xin/uPic/æ‰«ç _æœç´¢è”åˆä¼ æ’­æ ·å¼-æ ‡å‡†è‰²ç‰ˆ.png)
